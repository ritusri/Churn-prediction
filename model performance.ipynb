{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "   \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from random import randrange, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telcom=pd.read_csv(r\"C:\\Users\\anupr\\Desktop\\churn prediction\\churn_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "#gives model report in dataframe\n",
    "def model_report(model,training_x,testing_x,training_y,testing_y,name) :\n",
    "    model.fit(training_x,training_y)\n",
    "    predictions  = model.predict(testing_x)\n",
    "    accuracy     = accuracy_score(testing_y,predictions)\n",
    "    recallscore  = recall_score(testing_y,predictions)\n",
    "    precision    = precision_score(testing_y,predictions)\n",
    "    roc_auc      = roc_auc_score(testing_y,predictions)\n",
    "    f1score      = f1_score(testing_y,predictions) \n",
    "    kappa_metric = cohen_kappa_score(testing_y,predictions)\n",
    "    \n",
    "    df = pd.DataFrame({\"Model\"           : [name],\n",
    "                       \"Accuracy_score\"  : [accuracy],\n",
    "                       \"Recall_score\"    : [recallscore],\n",
    "                       \"Precision\"       : [precision],\n",
    "                       \"f1_score\"        : [f1score],\n",
    "                       \"Area_under_curve\": [roc_auc],\n",
    "                       \"Kappa_metric\"    : [kappa_metric],\n",
    "                      })\n",
    "    return df\n",
    "\n",
    "#outputs for every model\n",
    "model1 = model_report(logit,train_X,test_X,train_Y,test_Y,\n",
    "                      \"Logistic Regression(Baseline_model)\")\n",
    "model2 = model_report(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"Logistic Regression(SMOTE)\")\n",
    "model3 = model_report(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n",
    "                      \"Logistic Regression(RFE)\")\n",
    "decision_tree = DecisionTreeClassifier(max_depth = 9,\n",
    "                                       random_state = 123,\n",
    "                                       splitter  = \"best\",\n",
    "                                       criterion = \"gini\",\n",
    "                                      )\n",
    "model4 = model_report(decision_tree,train_X,test_X,train_Y,test_Y,\n",
    "                      \"Decision Tree\")\n",
    "model5 = model_report(knn,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"KNN Classifier\")\n",
    "rfc = RandomForestClassifier(n_estimators = 1000,\n",
    "                             random_state = 123,\n",
    "                             max_depth = 9,\n",
    "                             criterion = \"gini\")\n",
    "model6 = model_report(rfc,train_X,test_X,train_Y,test_Y,\n",
    "                      \"Random Forest Classifier\")\n",
    "model7 = model_report(gnb,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"Naive Bayes\")\n",
    "model8 = model_report(svc_lin,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"SVM Classifier Linear\")\n",
    "model9 = model_report(svc_rbf,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"SVM Classifier RBF\")\n",
    "model10 = model_report(lgbm_c,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"LGBM Classifier\")\n",
    "model11 = model_report(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                      \"XGBoost Classifier\")\n",
    "\n",
    "#concat all models\n",
    "model_performances = pd.concat([model1,model2,model3,\n",
    "                                model4,model5,model6,\n",
    "                                model7,model8,model9,\n",
    "                                model10,model11],axis = 0).reset_index()\n",
    "\n",
    "model_performances = model_performances.drop(columns = \"index\",axis =1)\n",
    "\n",
    "table  = ff.create_table(np.round(model_performances,4))\n",
    "\n",
    "py.iplot(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performances\n",
    "def output_tracer(metric,color) :\n",
    "    tracer = go.Bar(y = model_performances[\"Model\"] ,\n",
    "                    x = model_performances[metric],\n",
    "                    orientation = \"h\",name = metric ,\n",
    "                    marker = dict(line = dict(width =.7),\n",
    "                                  color = color)\n",
    "                   )\n",
    "    return tracer\n",
    "\n",
    "layout = go.Layout(dict(title = \"Model performances\",\n",
    "                        plot_bgcolor  = \"rgb(243,243,243)\",\n",
    "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
    "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     title = \"metric\",\n",
    "                                     zerolinewidth=1,\n",
    "                                     ticklen=5,gridwidth=2),\n",
    "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n",
    "                        margin = dict(l = 250),\n",
    "                        height = 780\n",
    "                       )\n",
    "                  )\n",
    "\n",
    "\n",
    "trace1  = output_tracer(\"Accuracy_score\",\"#6699FF\")\n",
    "trace2  = output_tracer('Recall_score',\"red\")\n",
    "trace3  = output_tracer('Precision',\"#33CC99\")\n",
    "trace4  = output_tracer('f1_score',\"lightgrey\")\n",
    "trace5  = output_tracer('Kappa_metric',\"#FFCC99\")\n",
    "\n",
    "data = [trace1,trace2,trace3,trace4,trace5]\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst    = [logit,logit_smote,decision_tree,knn,rfc,\n",
    "          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n",
    "\n",
    "length = len(lst)\n",
    "\n",
    "mods   = ['Logistic Regression(Baseline_model)','Logistic Regression(SMOTE)',\n",
    "          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n",
    "          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n",
    "          'XGBoost Classifier']\n",
    "\n",
    "fig = plt.figure(figsize=(13,15))\n",
    "fig.set_facecolor(\"#F3F3F3\")\n",
    "for i,j,k in itertools.zip_longest(lst,range(length),mods) :\n",
    "    plt.subplot(4,3,j+1)\n",
    "    predictions = i.predict(test_X)\n",
    "    conf_matrix = confusion_matrix(predictions,test_Y)\n",
    "    sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n",
    "                xticklabels=[\"not churn\",\"churn\"],\n",
    "                yticklabels=[\"not churn\",\"churn\"],\n",
    "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
    "    plt.title(k,color = \"b\")\n",
    "    plt.subplots_adjust(wspace = .3,hspace = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
